{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y79f1OLvRQtJ"
      },
      "source": [
        "# Activity Recognition in Video\n",
        "\n",
        "A major part of this notebook has been taken from [this example in Keras](https://keras.io/examples/vision/video_classification/).\n",
        "\n",
        "Some changes have been introduced such as using DeIT and ORB for feature extraction and a different method for sampling frames from the videos in the given dataset.\n",
        "\n",
        "<mark>This notebook just runs the model decribed in the aforementioned original notebook using **features extracted from the [pre-trained DeIT classifier](https://huggingface.co/docs/transformers/v4.27.2/en/model_doc/deit) provided by HuggingFace**.</mark>\n",
        "\n",
        "The DeIT model used here is provided in [this table](https://huggingface.co/facebook/deit-small-patch16-224) called <mark>DeiT-small</mark>.\n",
        "\n",
        "As in the original notebook we will be using a subset of the [UCF Activity Recognition dataset](https://www.crcv.ucf.edu/data/UCF101.php). We will not be modifying the hyperparameters except the *epoch* and *sampled sequence length*.\n",
        "\n",
        "<mark>NOTE: We have **decreased** the sampled sequence length as it takes a lot of time to extract the features of multiple frames of the video.</mark>\n",
        "\n",
        "*The model configuration used here will be kept constant except obviously the input size.* \n",
        "\n",
        "This is because we want to compare the models built using CNN, ORB and DeIT."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow=='2.7.0'"
      ],
      "metadata": {
        "id": "jKDbZXhAFejH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "946ec414-10d0-40df-bb30-b1fd0bf93e5e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.12.0\n",
            "Uninstalling tensorflow-2.12.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.9/dist-packages/tensorflow-2.12.0.dist-info/*\n",
            "    /usr/local/lib/python3.9/dist-packages/tensorflow/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled tensorflow-2.12.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.7.0\n",
            "  Downloading tensorflow-2.7.0-cp39-cp39-manylinux2010_x86_64.whl (489.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.7/489.7 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (4.5.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (0.4.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (16.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (1.16.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (0.40.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (3.8.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (1.53.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (0.32.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (1.14.1)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (1.4.0)\n",
            "Collecting keras<2.8,>=2.7.0rc0\n",
            "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
            "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.1/463.1 KB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (3.3.0)\n",
            "Collecting flatbuffers<3.0,>=1.12\n",
            "  Downloading flatbuffers-2.0.7-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (2.12.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (3.20.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (2.2.0)\n",
            "Collecting keras-preprocessing>=1.1.1\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7.0) (1.22.4)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.2.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.17.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (3.4.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (67.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.4.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (6.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.6->tensorflow==2.7.0) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, keras, flatbuffers, keras-preprocessing, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.3.3\n",
            "    Uninstalling flatbuffers-23.3.3:\n",
            "      Successfully uninstalled flatbuffers-23.3.3\n",
            "Successfully installed flatbuffers-2.0.7 keras-2.7.0 keras-preprocessing-1.1.2 tensorflow-2.7.0 tensorflow-estimator-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Dp0SUXpfRQtL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c790488-5fe3-4be9-de3c-10dec48f5022"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.9/dist-packages (4.6.6)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.9/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from gdown) (3.10.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->gdown) (2.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/tensorflow/docs\n",
        "!pip install transformers\n",
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En9SbOEnRQtO"
      },
      "source": [
        "## Data collection\n",
        "\n",
        "In order to keep the runtime of this example relatively short, we will be using a\n",
        "subsampled version of the original UCF101 dataset. You can refer to the notebook **dataset_subset_UCF.ipynb** in the repository to know how the subsampling was done.\n",
        "\n",
        "The dataset is provided in the following link.\n",
        "https://drive.google.com/file/d/1-1Jgmhg-84WbwZ8v9kvpFTDDpVUqRO1V/view?usp=share_link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4up7anqJRQtP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bb3618d-17ab-40a3-8877-e038eef8beed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-1Jgmhg-84WbwZ8v9kvpFTDDpVUqRO1V\n",
            "To: /content/ucf101_top10.tar.gz\n",
            "100% 1.04G/1.04G [00:19<00:00, 52.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1-1Jgmhg-84WbwZ8v9kvpFTDDpVUqRO1V\n",
        "!tar -xf /content/ucf101_top10.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCyA8mrNRQtQ"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lDowS7m1RQtR"
      },
      "outputs": [],
      "source": [
        "from tensorflow_docs.vis import embed\n",
        "from tensorflow import keras\n",
        "from imutils import paths\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import imageio\n",
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "from transformers import AutoFeatureExtractor, DeiTForImageClassificationWithTeacher\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaT0EeaERQtS"
      },
      "source": [
        "## Define hyperparameters\n",
        "\n",
        "\n",
        "\n",
        "1.   BATCH_SIZE - Number of inputs to train in a single iteration\n",
        "2. EPOCHS - Number of training iterations\n",
        "3. MAX_SEQ_LENGTH - Number of frames to be sampled from the image\n",
        "4. NUM_FEATURES - The size of the feature vector extracted from the image or frame encoder (in this case its DeIT)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jn_kmlEiRQtT"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 50              \n",
        "\n",
        "MAX_SEQ_LENGTH = 5\n",
        "NUM_FEATURES = 768"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBpS_mUlRQtV"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "H8B_wwX0RQtW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "711250db-6a25-4bbe-de1f-837d78aa86e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total videos for training: 1171\n",
            "Total videos for testing: 459\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       video_name            tag\n",
              "232        v_Drumming_g08_c01.avi       Drumming\n",
              "223     v_CricketShot_g24_c06.avi    CricketShot\n",
              "248        v_Drumming_g11_c01.avi       Drumming\n",
              "944    v_ShavingBeard_g09_c02.avi   ShavingBeard\n",
              "288        v_Drumming_g16_c07.avi       Drumming\n",
              "1067    v_TennisSwing_g10_c01.avi    TennisSwing\n",
              "422     v_HorseRiding_g19_c07.avi    HorseRiding\n",
              "772   v_PlayingGuitar_g19_c01.avi  PlayingGuitar\n",
              "1046   v_ShavingBeard_g24_c06.avi   ShavingBeard\n",
              "965    v_ShavingBeard_g12_c05.avi   ShavingBeard"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-19cf0f93-d696-4b85-9ab8-d108fcebf810\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_name</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>v_Drumming_g08_c01.avi</td>\n",
              "      <td>Drumming</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>v_CricketShot_g24_c06.avi</td>\n",
              "      <td>CricketShot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>v_Drumming_g11_c01.avi</td>\n",
              "      <td>Drumming</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>944</th>\n",
              "      <td>v_ShavingBeard_g09_c02.avi</td>\n",
              "      <td>ShavingBeard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288</th>\n",
              "      <td>v_Drumming_g16_c07.avi</td>\n",
              "      <td>Drumming</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1067</th>\n",
              "      <td>v_TennisSwing_g10_c01.avi</td>\n",
              "      <td>TennisSwing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422</th>\n",
              "      <td>v_HorseRiding_g19_c07.avi</td>\n",
              "      <td>HorseRiding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>772</th>\n",
              "      <td>v_PlayingGuitar_g19_c01.avi</td>\n",
              "      <td>PlayingGuitar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1046</th>\n",
              "      <td>v_ShavingBeard_g24_c06.avi</td>\n",
              "      <td>ShavingBeard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>965</th>\n",
              "      <td>v_ShavingBeard_g12_c05.avi</td>\n",
              "      <td>ShavingBeard</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19cf0f93-d696-4b85-9ab8-d108fcebf810')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-19cf0f93-d696-4b85-9ab8-d108fcebf810 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-19cf0f93-d696-4b85-9ab8-d108fcebf810');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "print(f\"Total videos for training: {len(train_df)}\")\n",
        "print(f\"Total videos for testing: {len(test_df)}\")\n",
        "\n",
        "train_df.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlTsglOoRQtX"
      },
      "source": [
        "We have used OpenCV's VideoCapture method to read each frame of the video.\n",
        "\n",
        "As set by the corresponding hyperparameter, we will sample MAX_SEQ_LENGTH frames (denote by $M$ for now). To do this we first get the total number of frames (say, $F$) present in the video file using the metadata included in the read object created by the VideoCapture method.\n",
        "\n",
        "Then we sample with step-size given by $⌊\\frac{F}{M}⌋$ and stop once the number of sampled frames reaches $M$ (or maybe below it)\n",
        "\n",
        "NOTE: The earlier implementation used to store all frames from all videos and then choose first MAX_SEQ_LENGTH frames to encode. We take the frames with the step-size mentioned above as this is equivalent and way more memory efficient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3xGTEioaRQtY"
      },
      "outputs": [],
      "source": [
        "def crop_center_square(frame):\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
        "\n",
        "\n",
        "def load_video(path, max_frames=0):\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    F = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))    #total number of frames in the video\n",
        "    M = max_frames                                #max sequence length required\n",
        "    S = max(int(np.floor(F/M)), 1)                #in case step-size goes to 0\n",
        "\n",
        "    frames = []\n",
        "    frame_count = 0\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            if frame_count%S == 0:                #sample only at steps\n",
        "              frame = crop_center_square(frame)\n",
        "              frames.append(frame)\n",
        "\n",
        "            frame_count += 1                      #update number of frames read\n",
        "            \n",
        "            #break if we reach end of video or maximum required frames read  \n",
        "            if frame_count==F or len(frames) == M:         \n",
        "                break\n",
        "    finally:\n",
        "        cap.release()\n",
        "    return np.array(frames)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPHG5kHTRQta"
      },
      "source": [
        "The input pre-processing is done by the AutoFeatureExtractor module provided by HuggingFace which transforms the input as per the requirement of the pre-trained model loaded. \n",
        "\n",
        "We have to define a forward hook that takes the activation of the class token from the DeIT encoder (before it is used to generate the class and distillation outputs). The class token has been chosen as this is the token that interacts with the other patch tokens along with the distillation token and is used to make the final prediction of the class.\n",
        "\n",
        "For more details about the forward hook and the steps for feature extraction using DeIT model please check the notebook *DeIT_Feature_Extraction_Example.ipynb* provided in the repository."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load the pre-trained model and init the feature extractor\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained('facebook/deit-base-distilled-patch16-224')\n",
        "deit_model = DeiTForImageClassificationWithTeacher.from_pretrained('facebook/deit-base-distilled-patch16-224')"
      ],
      "metadata": {
        "id": "cn-biKvnaJ3A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "4e367bec4c854269860d487c36a814db",
            "3185a6cb0cf8444ba9d6bfbd5da2663a",
            "add526738eed4349a1048ac331287b5f",
            "265f8cc08e4b4550863071ac007bddff",
            "bc7d3158adbe4e5d8c23b9ffa2071caa",
            "2f87f78affbb409aaaed47f4eb6446a4",
            "b3f535c66ac9429182861fecf3270a33",
            "31406237b11941afaa5245734d54ec50",
            "3c41cad8fc864f5da00121de4834850c",
            "1cecc248d85a490aa8257affa5a0716b",
            "85a4c44daacf430fac865951576607f2",
            "0d471a92af8d4854a113a02dd79d655f",
            "e0a6492e3dbe44289fc1f55f1d12cbd3",
            "c9e91200a60c4e2ca06b61e8e84655ef",
            "650d99ae319d4db58d78cf5b74249b96",
            "c5ef0aa9daf54320ab722658ff973579",
            "b9f081cd6ad24205bedd527d2f36abad",
            "63ee122621d8413b9fbb95b54fa6b4bb",
            "7d2f5e8bcc6849e0827c43ea95b43f99",
            "3bbc2d48b91a4da5a4ac549107f25ffe",
            "428dc06424b2443cb961bb360eb1eeb5",
            "929fdce7f8c6479f8db1a6ff7b2d2d53",
            "d374cfa9d63b4722bb3c1a240bd702e0",
            "476fcb33b8a9468eb616786716031c0c",
            "4df50d1883fc42f786ffbfe1df1a583c",
            "0822af8c8e884b0881ed1c999ba8d00c",
            "e7917e47baa042699a5c12d17ffc6875",
            "f8237facda104a2c99c12b9280eb1143",
            "9dc11776e6c9413787b9bfd1f1dab53d",
            "6e75f19e3e1a47359578eabbdc4775f9",
            "5698e14b017d441d8a0167357c77226a",
            "30cb99d18cac45f089ef537542c509e5",
            "56271ec0256942b4b550ff955c7906f4"
          ]
        },
        "outputId": "e9271a37-4f57-47a0-bb2d-d784d10feb49"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)rocessor_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e367bec4c854269860d487c36a814db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/models/deit/feature_extraction_deit.py:28: FutureWarning: The class DeiTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use DeiTImageProcessor instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/69.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d471a92af8d4854a113a02dd79d655f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/349M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d374cfa9d63b4722bb3c1a240bd702e0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define the hook callable\n",
        "activation = {}\n",
        "\n",
        "def getActivation(name):\n",
        "    # the hook signature\n",
        "    def hook(model, input, output):\n",
        "      try:\n",
        "        activation[name] = output.detach()\n",
        "      except:\n",
        "        activation[name] = output\n",
        "    return hook\n",
        "\n",
        "#attach hooks to get intermediate activation\n",
        "deit_encoder = deit_model.deit.register_forward_hook(getActivation('deit_encoder'))"
      ],
      "metadata": {
        "id": "T6r5FfQTaQM9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lNK-3S5JRQtb"
      },
      "outputs": [],
      "source": [
        "#define the feature extractor\n",
        "def deit_feature_extractor(image):\n",
        "  inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
        "  outputs = deit_model(**inputs)\n",
        "\n",
        "  feature = activation['deit_encoder'][0][ : , 0, : ].detach().numpy()\n",
        "  return feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvNiaRRkRQtb"
      },
      "source": [
        "The labels of the videos are strings. Neural networks do not understand string values,\n",
        "so they must be converted to some numerical form before they are fed to the model. Here\n",
        "we will use the [`StringLookup`](https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup)\n",
        "layer encode the class labels as integers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jtQpEw56RQtc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e34472e8-bda3-46a8-bb74-f6f18db0c694"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['BoxingPunchingBag', 'CricketShot', 'Drumming', 'HorseRiding', 'PlayingCello', 'PlayingDhol', 'PlayingGuitar', 'Punch', 'ShavingBeard', 'TennisSwing']\n"
          ]
        }
      ],
      "source": [
        "label_processor = keras.layers.StringLookup(\n",
        "    num_oov_indices=0, vocabulary=np.unique(train_df[\"tag\"])\n",
        ")\n",
        "print(label_processor.get_vocabulary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bk1ZjjitRQtd"
      },
      "source": [
        "Finally, we can put all the pieces together to create our data processing utility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "z4CEfMXfRQte"
      },
      "outputs": [],
      "source": [
        "\n",
        "def prepare_all_videos(df, root_dir, max_frames = 10):\n",
        "    num_samples = len(df)\n",
        "    video_paths = df[\"video_name\"].values.tolist()\n",
        "    labels = df[\"tag\"].values\n",
        "    labels = label_processor(labels[..., None]).numpy()\n",
        "\n",
        "    # `frame_masks` and `frame_features` are what we will feed to our sequence model.\n",
        "    # `frame_masks` will contain a bunch of booleans denoting if a timestep is\n",
        "    # masked with padding or not.\n",
        "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
        "    frame_features = np.zeros(\n",
        "        shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
        "    )\n",
        "\n",
        "    # For each video.\n",
        "    for idx, path in enumerate(tqdm(video_paths)):\n",
        "        # Gather all its frames and add a batch dimension.\n",
        "        frames = load_video(os.path.join(root_dir, path), max_frames)\n",
        "        frames = frames[None, ...]\n",
        "\n",
        "#         # Initialize placeholders to store the masks and features of the current video.\n",
        "        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "        temp_frame_features = np.zeros(\n",
        "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
        "        )\n",
        "\n",
        "        # Extract features from the frames of the current video.\n",
        "        for i, batch in enumerate(frames):\n",
        "            length = batch.shape[0]\n",
        "            assert length == MAX_SEQ_LENGTH, \"sequence length not sufficient!\"\n",
        "            for j in range(length):\n",
        "                temp_frame_features[i, j, :] = deit_feature_extractor(batch[j, : ])\n",
        "            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
        "\n",
        "        frame_features[idx,] = temp_frame_features.squeeze()\n",
        "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
        "\n",
        "    return (frame_features, frame_masks), labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, train_labels = prepare_all_videos(train_df, \"train\", max_frames=MAX_SEQ_LENGTH)\n",
        "test_data, test_labels = prepare_all_videos(test_df, \"test\", max_frames=MAX_SEQ_LENGTH)"
      ],
      "metadata": {
        "id": "7zQSW9DaDpis",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a63fea16-305a-4813-b2a4-3129e2623b9e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1171/1171 [48:57<00:00,  2.51s/it]\n",
            "100%|██████████| 459/459 [18:42<00:00,  2.44s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
        "print(f\"Frame masks in train set: {train_data[1].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwRD-XhWkxFd",
        "outputId": "eb9a44f1-46ed-4c29-f824-d3cef713f84f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frame features in train set: (1171, 5, 768)\n",
            "Frame masks in train set: (1171, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHX4G9c_RQtg"
      },
      "source": [
        "## The sequence model\n",
        "\n",
        "Now, we can feed this data to a sequence model consisting of recurrent layers like `GRU`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5LL0ijrFRQth"
      },
      "outputs": [],
      "source": [
        "# Utility for our sequence model.\n",
        "def get_sequence_model():\n",
        "    class_vocab = label_processor.get_vocabulary()\n",
        "\n",
        "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
        "    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "\n",
        "    # Refer to the following tutorial to understand the significance of using `mask`:\n",
        "    # https://keras.io/api/layers/recurrent_layers/gru/\n",
        "    x = keras.layers.GRU(128, return_sequences=True)(\n",
        "        frame_features_input, mask=mask_input\n",
        "    )\n",
        "    x = keras.layers.Dropout(0.4)(x)\n",
        "    x = keras.layers.GRU(64)(x)\n",
        "    x = keras.layers.Dropout(0.2)(x)\n",
        "    x = keras.layers.Dense(32, activation=\"relu\")(x)\n",
        "    output = keras.layers.Dense(len(class_vocab), activation=\"softmax\")(x)\n",
        "\n",
        "    rnn_model = keras.Model([frame_features_input, mask_input], output)\n",
        "    rnn_model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics='sparse_categorical_accuracy')\n",
        "    \n",
        "    return rnn_model\n",
        "\n",
        "\n",
        "# Utility for running experiments.\n",
        "def run_experiment(seq_model):\n",
        "\n",
        "    history = seq_model.fit(\n",
        "        [train_data[0], train_data[1]],\n",
        "        train_labels,\n",
        "        epochs=EPOCHS\n",
        "    )\n",
        "\n",
        "    test_metrics = seq_model.evaluate([test_data[0], test_data[1]], test_labels)\n",
        "    print(f\" {test_metrics}\")\n",
        "\n",
        "    return history, seq_model, test_metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_sequence_model()\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uW-10xRiSSS",
        "outputId": "0182c162-0f71-417b-ed6e-0dd07ba22e01"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 5, 768)]     0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 5)]          0           []                               \n",
            "                                                                                                  \n",
            " gru (GRU)                      (None, 5, 128)       344832      ['input_1[0][0]',                \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 5, 128)       0           ['gru[0][0]']                    \n",
            "                                                                                                  \n",
            " gru_1 (GRU)                    (None, 64)           37248       ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 64)           0           ['gru_1[0][0]']                  \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 32)           2080        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 10)           330         ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 384,490\n",
            "Trainable params: 384,490\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fit model\n",
        "training_hist, sequence_model, test_metrics = run_experiment(model)"
      ],
      "metadata": {
        "id": "y3oMqWLBdPVd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a6d76d0-a5e3-4c27-fc7f-35ea7b619308"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "37/37 [==============================] - 13s 10ms/step - loss: 0.8916 - sparse_categorical_accuracy: 0.8318\n",
            "Epoch 2/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0743 - sparse_categorical_accuracy: 0.9991\n",
            "Epoch 3/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0218 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 0.0130 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0081 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0063 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0047 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 0.0038 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 0.0032 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "37/37 [==============================] - 1s 19ms/step - loss: 0.0025 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "37/37 [==============================] - 1s 18ms/step - loss: 0.0021 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "37/37 [==============================] - 1s 19ms/step - loss: 0.0018 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "37/37 [==============================] - 1s 20ms/step - loss: 0.0016 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "37/37 [==============================] - 1s 20ms/step - loss: 0.0014 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "37/37 [==============================] - 1s 19ms/step - loss: 0.0012 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "37/37 [==============================] - 1s 19ms/step - loss: 0.0010 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "37/37 [==============================] - 1s 14ms/step - loss: 0.0011 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 8.5620e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 8.0435e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 6.6614e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 7.0744e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 6.2714e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 5.8361e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 5.2205e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 5.2721e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 4.3146e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 4.1695e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 4.0376e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 3.8189e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 3.6057e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 3.5471e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 3.0626e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 2.9183e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.7076e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.5647e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.6393e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.3076e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.4203e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.9116e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2.0118e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1.9957e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1.8014e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "37/37 [==============================] - 1s 16ms/step - loss: 1.7632e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "37/37 [==============================] - 1s 18ms/step - loss: 1.9146e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "37/37 [==============================] - 1s 21ms/step - loss: 1.5132e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "37/37 [==============================] - 1s 21ms/step - loss: 1.7110e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "37/37 [==============================] - 1s 21ms/step - loss: 1.3894e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "37/37 [==============================] - 1s 21ms/step - loss: 1.4027e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "37/37 [==============================] - 1s 20ms/step - loss: 1.3005e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "37/37 [==============================] - 1s 16ms/step - loss: 1.2942e-04 - sparse_categorical_accuracy: 1.0000\n",
            "15/15 [==============================] - 2s 5ms/step - loss: 0.1660 - sparse_categorical_accuracy: 0.9630\n",
            " [0.16603580117225647, 0.9629629850387573]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save model\n",
        "model.save('activity_recog_deit_gru')"
      ],
      "metadata": {
        "id": "4XQ9xQ2EvgJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -cf activity_recog_deit_gru.tgz activity_recog_deit_gru"
      ],
      "metadata": {
        "id": "9uElE_eyxt6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(training_hist.history['loss'], label = 'training loss')\n",
        "plt.plot(training_hist.history['sparse_categorical_accuracy'], label = 'training acc')\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plot_txt = f\"Test Accuracy: {round(test_metrics[-1], 3)}\"\n",
        "plt.text(30, 0.1, plot_txt, fontsize=8, backgroundcolor='lime')\n",
        "plt.title('Training loss plot of DeIT-GRU Approach')\n",
        "plt.savefig('training_DeIT_GRU_model.pdf')"
      ],
      "metadata": {
        "id": "xqVcO5A5YDwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5gg7-E5RQtj"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gF01FBqURQtj"
      },
      "outputs": [],
      "source": [
        "\n",
        "def prepare_single_video(frames):\n",
        "    frames = frames[None, ...]\n",
        "    frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
        "\n",
        "    for i, batch in enumerate(frames):\n",
        "        length = batch.shape[0]\n",
        "        assert length == MAX_SEQ_LENGTH, \"sequence length not sufficient!\"\n",
        "        for j in range(length):\n",
        "          frame_features[i, j, :] = deit_feature_extractor(batch[j, :])\n",
        "        \n",
        "        frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
        "\n",
        "    return frame_features, frame_mask\n",
        "\n",
        "\n",
        "def sequence_prediction(path):\n",
        "    class_vocab = label_processor.get_vocabulary()\n",
        "\n",
        "    frames = load_video(os.path.join(\"test\", path), max_frames=MAX_SEQ_LENGTH)\n",
        "    frame_features, frame_mask = prepare_single_video(frames)\n",
        "    probabilities = sequence_model.predict([frame_features, frame_mask])[0]\n",
        "\n",
        "    for i in np.argsort(probabilities)[::-1]:\n",
        "        print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n",
        "    return frames\n",
        "\n",
        "\n",
        "# This utility is for visualization.\n",
        "# Referenced from:\n",
        "# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\n",
        "def to_gif(images):\n",
        "    for i in range(images.shape[0]):\n",
        "      images[i] = cv2.cvtColor(images[i], cv2.COLOR_BGR2RGB)\n",
        "    converted_images = images.astype(np.uint8)\n",
        "    imageio.mimsave(\"animation.gif\", converted_images, fps=10)\n",
        "    return embed.embed_file(\"animation.gif\")\n",
        "\n",
        "\n",
        "test_video = np.random.choice(test_df[\"video_name\"].values.tolist())\n",
        "print(f\"Test video path: {test_video}\")\n",
        "test_frames = sequence_prediction(test_video)\n",
        "to_gif(test_frames)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#one good habit - remove the hook\n",
        "deit_encoder.remove()\n"
      ],
      "metadata": {
        "id": "s3OW-iE7j4Rt"
      },
      "execution_count": 22,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4e367bec4c854269860d487c36a814db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3185a6cb0cf8444ba9d6bfbd5da2663a",
              "IPY_MODEL_add526738eed4349a1048ac331287b5f",
              "IPY_MODEL_265f8cc08e4b4550863071ac007bddff"
            ],
            "layout": "IPY_MODEL_bc7d3158adbe4e5d8c23b9ffa2071caa"
          }
        },
        "3185a6cb0cf8444ba9d6bfbd5da2663a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f87f78affbb409aaaed47f4eb6446a4",
            "placeholder": "​",
            "style": "IPY_MODEL_b3f535c66ac9429182861fecf3270a33",
            "value": "Downloading (…)rocessor_config.json: 100%"
          }
        },
        "add526738eed4349a1048ac331287b5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31406237b11941afaa5245734d54ec50",
            "max": 287,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c41cad8fc864f5da00121de4834850c",
            "value": 287
          }
        },
        "265f8cc08e4b4550863071ac007bddff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cecc248d85a490aa8257affa5a0716b",
            "placeholder": "​",
            "style": "IPY_MODEL_85a4c44daacf430fac865951576607f2",
            "value": " 287/287 [00:00&lt;00:00, 11.5kB/s]"
          }
        },
        "bc7d3158adbe4e5d8c23b9ffa2071caa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f87f78affbb409aaaed47f4eb6446a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3f535c66ac9429182861fecf3270a33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31406237b11941afaa5245734d54ec50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c41cad8fc864f5da00121de4834850c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1cecc248d85a490aa8257affa5a0716b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85a4c44daacf430fac865951576607f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d471a92af8d4854a113a02dd79d655f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0a6492e3dbe44289fc1f55f1d12cbd3",
              "IPY_MODEL_c9e91200a60c4e2ca06b61e8e84655ef",
              "IPY_MODEL_650d99ae319d4db58d78cf5b74249b96"
            ],
            "layout": "IPY_MODEL_c5ef0aa9daf54320ab722658ff973579"
          }
        },
        "e0a6492e3dbe44289fc1f55f1d12cbd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9f081cd6ad24205bedd527d2f36abad",
            "placeholder": "​",
            "style": "IPY_MODEL_63ee122621d8413b9fbb95b54fa6b4bb",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "c9e91200a60c4e2ca06b61e8e84655ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d2f5e8bcc6849e0827c43ea95b43f99",
            "max": 69607,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bbc2d48b91a4da5a4ac549107f25ffe",
            "value": 69607
          }
        },
        "650d99ae319d4db58d78cf5b74249b96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_428dc06424b2443cb961bb360eb1eeb5",
            "placeholder": "​",
            "style": "IPY_MODEL_929fdce7f8c6479f8db1a6ff7b2d2d53",
            "value": " 69.6k/69.6k [00:00&lt;00:00, 157kB/s]"
          }
        },
        "c5ef0aa9daf54320ab722658ff973579": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9f081cd6ad24205bedd527d2f36abad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63ee122621d8413b9fbb95b54fa6b4bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d2f5e8bcc6849e0827c43ea95b43f99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bbc2d48b91a4da5a4ac549107f25ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "428dc06424b2443cb961bb360eb1eeb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "929fdce7f8c6479f8db1a6ff7b2d2d53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d374cfa9d63b4722bb3c1a240bd702e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_476fcb33b8a9468eb616786716031c0c",
              "IPY_MODEL_4df50d1883fc42f786ffbfe1df1a583c",
              "IPY_MODEL_0822af8c8e884b0881ed1c999ba8d00c"
            ],
            "layout": "IPY_MODEL_e7917e47baa042699a5c12d17ffc6875"
          }
        },
        "476fcb33b8a9468eb616786716031c0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8237facda104a2c99c12b9280eb1143",
            "placeholder": "​",
            "style": "IPY_MODEL_9dc11776e6c9413787b9bfd1f1dab53d",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "4df50d1883fc42f786ffbfe1df1a583c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e75f19e3e1a47359578eabbdc4775f9",
            "max": 349435207,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5698e14b017d441d8a0167357c77226a",
            "value": 349435207
          }
        },
        "0822af8c8e884b0881ed1c999ba8d00c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30cb99d18cac45f089ef537542c509e5",
            "placeholder": "​",
            "style": "IPY_MODEL_56271ec0256942b4b550ff955c7906f4",
            "value": " 349M/349M [00:18&lt;00:00, 19.6MB/s]"
          }
        },
        "e7917e47baa042699a5c12d17ffc6875": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8237facda104a2c99c12b9280eb1143": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dc11776e6c9413787b9bfd1f1dab53d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e75f19e3e1a47359578eabbdc4775f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5698e14b017d441d8a0167357c77226a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30cb99d18cac45f089ef537542c509e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56271ec0256942b4b550ff955c7906f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}